{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a sequence in the following data format:\n",
    "* *x* and *y* describing a position in a grid of `100 x 100`\n",
    "* *c* describing a control status with 3 possible states (0 = starting, 1 = holding, 2 = pausing)\n",
    "\n",
    "State transitions follow this diagram:\n",
    "\n",
    "```\n",
    "+-+     +-+     +-+\n",
    "|0| --> |1| --> |2|\n",
    "+++  ^  +++  ^  +++\n",
    " ^   |   |   |   |\n",
    " |   |   |   |   |\n",
    " +---+---+   +---+\n",
    " |               |\n",
    " |               |\n",
    " +---------------+\n",
    "```\n",
    "\n",
    "This results in `100 x 100 x 3 = 30.000` possible one-hot encoded values ranging from 1 - 30.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES_COUNT = 3\n",
    "\n",
    "STATE_STARTING = 0\n",
    "STATE_HOLDING = 1\n",
    "STATE_PAUSING = 2\n",
    "\n",
    "DEFAULT_POSITION = [0, 0]\n",
    "\n",
    "\n",
    "def random_position(grid_size):\n",
    "    return [random.randint(0, grid_size - 1) for _ in range(2)]\n",
    "    \n",
    "\n",
    "def next_state(previous_state):\n",
    "    if previous_state == STATE_STARTING:\n",
    "        next_state = STATE_HOLDING\n",
    "    elif previous_state == STATE_HOLDING:\n",
    "        next_state = random.choice([\n",
    "            STATE_STARTING,\n",
    "            STATE_HOLDING,\n",
    "            STATE_PAUSING\n",
    "        ])\n",
    "    elif previous_state == STATE_PAUSING:\n",
    "        next_state = random.choice([\n",
    "            STATE_STARTING,\n",
    "            STATE_PAUSING\n",
    "        ])\n",
    "    else:\n",
    "        next_state = random.choice([\n",
    "            STATE_STARTING,\n",
    "            STATE_PAUSING\n",
    "        ])\n",
    "    return next_state\n",
    "    \n",
    "\n",
    "def generate_sequence(grid_size, seq_len):\n",
    "    sequence = []\n",
    "    current_state = None\n",
    "    current_position = DEFAULT_POSITION\n",
    "    for i in range(seq_len):\n",
    "        current_state = next_state(current_state)\n",
    "        if current_state == STATE_STARTING:\n",
    "            current_position = random_position(grid_size)\n",
    "        elif current_state == STATE_PAUSING:\n",
    "            current_position = DEFAULT_POSITION\n",
    "        feature_vector = np.concatenate([current_position, [current_state]])\n",
    "        sequence.append(feature_vector)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def generate_alternative_sequence(seq, grid_size):\n",
    "    sequence = generate_sequence(grid_size, len(seq))\n",
    "    current_position = None\n",
    "    for i in range(len(seq)):\n",
    "        if sequence[i][2] == STATE_STARTING:\n",
    "            # \"react\" to other sequence by flipping it\n",
    "            if seq[i][2] != STATE_PAUSING:\n",
    "                current_position = [seq[i][1], seq[i][0]]\n",
    "                sequence[i][0] = current_position[0]\n",
    "                sequence[i][1] = current_position[1]\n",
    "            else:\n",
    "                current_position= None\n",
    "        elif sequence[i][2] == STATE_HOLDING:\n",
    "            if current_position:\n",
    "                sequence[i][0] = current_position[0]\n",
    "                sequence[i][1] = current_position[1]\n",
    "    return sequence\n",
    "    \n",
    "\n",
    "def encode_sequence(seq, grid_size, pad=False):\n",
    "    # Encode 3-d vector in index values\n",
    "    m = np.zeros((grid_size, grid_size, STATES_COUNT))\n",
    "    indexed = [np.ravel_multi_index(vector, m.shape) + 1 for vector in seq]\n",
    "    if pad:\n",
    "        indexed = [0] + indexed[:-1]\n",
    "    n_tokens = (grid_size * grid_size * STATES_COUNT) + 1\n",
    "    hot_encoded = keras.utils.to_categorical(indexed, num_classes=n_tokens)\n",
    "    return hot_encoded\n",
    "\n",
    "\n",
    "def decode_sequence(seq, grid_size):\n",
    "    m = np.zeros((grid_size, grid_size, STATES_COUNT))\n",
    "    one_hot_decoded = [np.argmax(vector) for vector in seq]\n",
    "    decoded = [np.unravel_index((val - 1 if val > 0 else 0), m.shape) for val in one_hot_decoded]\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def generate_dataset(grid_size, n_in, n_out, n_samples):\n",
    "    src_data, start_data, target_data = [], [], []\n",
    "    for i in range(n_samples):\n",
    "        # Generate source sequence\n",
    "        src = generate_sequence(grid_size, n_in)\n",
    "        src_encoded = encode_sequence(src, grid_size)\n",
    "        # Generate target sequence\n",
    "        target = generate_alternative_sequence(src[:n_out], grid_size)\n",
    "        target_encoded = encode_sequence(target, grid_size)\n",
    "        # Generated target input sequence, begin with start symbol 0\n",
    "        start_encoded = encode_sequence(target, grid_size, pad=True)\n",
    "        # ... add to dataset\n",
    "        src_data.append(src_encoded)\n",
    "        start_data.append(start_encoded)\n",
    "        target_data.append(target_encoded)\n",
    "        if i % 10000 == 0 and i > 0:\n",
    "            print(\"Generated sample no. #%d\" % i)\n",
    "    return np.array(src_data), np.array(start_data), np.array(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES_COUNT = 3\n",
    "\n",
    "def generate_sequence(length, n_unique):\n",
    "    return [random.randint(1, n_unique-1) for _ in range(length)]\n",
    "\n",
    "\n",
    "def generate_dataset(cardinality, n_in, n_out, n_samples):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for _ in range(n_samples):\n",
    "        # generate source sequence\n",
    "        source = generate_sequence(n_in, cardinality)\n",
    "        # define target sequence\n",
    "        target = source[:n_out]\n",
    "        target.reverse()\n",
    "        # create padded input target sequence\n",
    "        target_in = [0] + target[:-1]\n",
    "        # encode\n",
    "        src_encoded = keras.utils.to_categorical([source], num_classes=cardinality)\n",
    "        tar_encoded = keras.utils.to_categorical([target], num_classes=cardinality)\n",
    "        tar2_encoded = keras.utils.to_categorical([target_in], num_classes=cardinality)\n",
    "        # store\n",
    "        X1.append(src_encoded)\n",
    "        X2.append(tar2_encoded)\n",
    "        y.append(tar_encoded)\n",
    "    return array(X1), array(X2), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(grid_size, latent_dim, n_tokens):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None, n_tokens))\n",
    "    encoder = LSTM(latent_dim,\n",
    "                   dropout=0.2,\n",
    "                   return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, n_tokens))\n",
    "    decoder_lstm = LSTM(latent_dim,\n",
    "                        return_sequences=True,\n",
    "                        return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(\n",
    "        decoder_inputs,\n",
    "        initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # Define sampling models\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    # Define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    # Return all models\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "\n",
    "def train(model, encoder_input, decoder_input, decoder_target, epochs, batch_size):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit([encoder_input, decoder_input], decoder_target,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2)\n",
    "    return history\n",
    "\n",
    "\n",
    "def sample(encoder_model, decoder_model, input_seq, num_decoder_tokens, n_steps):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate an empty target sequence\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Sampling loop for a batch of sequences\n",
    "    sequence = []\n",
    "    for t in range(n_steps):\n",
    "        # Predict next vector\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        # Store prediction to new sequence\n",
    "        sequence.append(output_tokens[0, 0, :])\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        # Update target sequence\n",
    "        target_seq = output_tokens\n",
    "    return np.array(sequence)\n",
    "\n",
    "\n",
    "def evaluate(encoder_model, decoder_model, evaluation_total, n_tokens, n_in, n_out, grid_size):\n",
    "    evaluation_correct = 0\n",
    "    for _ in range(evaluation_total):\n",
    "        # Generate a test dataset\n",
    "        encoder_test, decoder_test, target_test = generate_dataset(\n",
    "            grid_size, n_in, n_out, 1)\n",
    "        # Sample some sequences with out trained model\n",
    "        target = sample(encoder_model, decoder_model, encoder_test, n_tokens, n_out)\n",
    "        if np.array_equal(\n",
    "            decode_sequence(target_test[0], grid_size),\n",
    "            decode_sequence(target, grid_size)):\n",
    "            evaluation_correct += 1\n",
    "    print(\"Accuracy: %.2f%%\" % (\n",
    "        float(evaluation_correct) / float(evaluation_total) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "Number of dataset samples:\t 100000\n",
      "Number of unique tokens:\t 28\n",
      "_______________________________________\n",
      "Sequence length for inputs:\t 5\n",
      "Sequence length for outputs:\t 5\n",
      "_______________________________________\n",
      "Epochs:\t\t\t\t 10\n",
      "Batch size:\t\t\t 512\n",
      "Latent space dimension:\t\t 256\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "grid_size = 3 # How large is the grid of our x/y vectors\n",
    "\n",
    "n_in = 5 # Length of an input sequence\n",
    "n_out = 5 # Length of an output sequence\n",
    "\n",
    "n_dataset_samples = 100000 # Number of samples to train on\n",
    "latent_dim = 256 # Latent dimensionality of the encoding space\n",
    "batch_size = 512 # Batch size for training\n",
    "epochs = 10 # Number of epochs to train for\n",
    "\n",
    "n_evaluation = 100 # Number of samples to evaluate\n",
    "n_samples = 10 # Number of samples to generate as an example\n",
    "\n",
    "# All x/y positions in grid * state variants + 1 start symbol\n",
    "n_tokens = (grid_size * grid_size * STATES_COUNT) + 1\n",
    "\n",
    "# Print current configuration\n",
    "print(\"=======================================\")\n",
    "print(\"Number of dataset samples:\\t %d\" % n_dataset_samples)\n",
    "print(\"Number of unique tokens:\\t %d\" % n_tokens)\n",
    "print(\"_______________________________________\")\n",
    "print(\"Sequence length for inputs:\\t %d\" % n_in)\n",
    "print(\"Sequence length for outputs:\\t %d\" % n_out)\n",
    "print(\"_______________________________________\")\n",
    "print(\"Epochs:\\t\\t\\t\\t %d\" % epochs)\n",
    "print(\"Batch size:\\t\\t\\t %d\" % batch_size)\n",
    "print(\"Latent space dimension:\\t\\t %d\" % latent_dim)\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'randint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-42887154a0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate a simulated dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m encoder_input_data, decoder_input_data, decoder_target_data = generate_dataset(\n\u001b[0;32m----> 3\u001b[0;31m     grid_size, n_in, n_out, n_dataset_samples)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print(\"Done! Shapes:\", encoder_input_data.shape,\n",
      "\u001b[0;32m<ipython-input-4-2f53d88cd62c>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(cardinality, n_in, n_out, n_samples)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# generate source sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# define target sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2f53d88cd62c>\u001b[0m in \u001b[0;36mgenerate_sequence\u001b[0;34m(length, n_unique)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_unique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_unique\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2f53d88cd62c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_unique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_unique\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'randint' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate a simulated dataset\n",
    "encoder_input_data, decoder_input_data, decoder_target_data = generate_dataset(\n",
    "    grid_size, n_in, n_out, n_dataset_samples)\n",
    "\n",
    "print(\"Done! Shapes:\", encoder_input_data.shape,\n",
    "      decoder_input_data.shape,\n",
    "      decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9ac28532802b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-fa98957c9906>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(grid_size, n_in, n_out, n_samples)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Generate target sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#generate_alternative_sequence(src[:n_out], grid_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtarget_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Generated target input sequence, begin with start symbol 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mstart_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-fa98957c9906>\u001b[0m in \u001b[0;36mencode_sequence\u001b[0;34m(seq, grid_size, pad)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Encode 3-d vector in index values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel_multi_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "generate_dataset(grid_size, n_in, n_out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, 256), (None, 291840      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, None, 256),  291840      input_22[0][0]                   \n",
      "                                                                 lstm_11[0][1]                    \n",
      "                                                                 lstm_11[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 28)     7196        lstm_12[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 590,876\n",
      "Trainable params: 590,876\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 40s 505us/step - loss: 1.8595 - acc: 0.4554 - val_loss: 1.1213 - val_acc: 0.5872\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 40s 501us/step - loss: 1.0793 - acc: 0.5844 - val_loss: 1.0139 - val_acc: 0.5883\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 40s 498us/step - loss: 1.0184 - acc: 0.5877 - val_loss: 0.9737 - val_acc: 0.5895\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 40s 496us/step - loss: 0.9908 - acc: 0.5872 - val_loss: 0.9611 - val_acc: 0.5885\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 40s 503us/step - loss: 0.9711 - acc: 0.5884 - val_loss: 0.9469 - val_acc: 0.5880\n",
      "Epoch 6/10\n",
      "32256/80000 [===========>..................] - ETA: 27s - loss: 0.9624 - acc: 0.5905"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-087afd56a2a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 batch_size)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-26691e18a7a6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, encoder_input, decoder_input, decoder_target, epochs, batch_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m               validation_split=0.2)\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/notebook/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/notebook/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/notebook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/notebook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/notebook/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "model, encoder_model, decoder_model = define_models(\n",
    "    grid_size,\n",
    "    latent_dim,\n",
    "    n_tokens)\n",
    "\n",
    "# Train the model\n",
    "history = train(model,\n",
    "                encoder_input_data,\n",
    "                decoder_input_data,\n",
    "                decoder_target_data,\n",
    "                epochs,\n",
    "                batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "evaluate(encoder_model,\n",
    "         decoder_model,\n",
    "         n_evaluation,\n",
    "         n_tokens,\n",
    "         n_in,\n",
    "         n_out,\n",
    "         grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a few examples\n",
    "for i in range(n_samples):\n",
    "    # Generate a sample dataset\n",
    "    encoder_test, decoder_test, target_test = generate_dataset(\n",
    "        grid_size,\n",
    "        n_in,\n",
    "        n_out,\n",
    "        1)\n",
    "    \n",
    "    # Sample some sequences with out trained model\n",
    "    target = sample(encoder_model,\n",
    "                    decoder_model,\n",
    "                    encoder_test,\n",
    "                    n_tokens,\n",
    "                    n_out)\n",
    "    \n",
    "    # Print it!\n",
    "    print('Sample #%i:\\nencoder_test=%s\\ntarget_test=%s\\ntarget=%s\\n' % (\n",
    "        i,\n",
    "        decode_sequence(encoder_test[0], grid_size),\n",
    "        decode_sequence(target_test[0], grid_size),\n",
    "        decode_sequence(target, grid_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a plot\n",
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
