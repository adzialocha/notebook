{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pretty_midi as midi\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning applications we are interested in preprocessing MIDI files of different orchestra works into a simplified, standardized format:\n",
    "\n",
    "* Quantize notes\n",
    "* Transpose all notes (octaves) within a fixed range\n",
    "* Convert parts to one time signature\n",
    "* Remove parts which are too sparse\n",
    "* Reduce all parts to a fixed number\n",
    "\n",
    "Through different techniques we want to augment the data:\n",
    "\n",
    "* Transpose score to all keys (does not happen in this part)\n",
    "* Through part reduction we deal with unused material, we use this material to generate new score material, changing the original score but keeping the \"style\" of the composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output files\n",
    "PATH_IN = './files/midi/symphony.mid'\n",
    "PATH_OUT = './files/midi/symphony-converted.mid'\n",
    "\n",
    "# Transpose all notes between this range (MIDI)\n",
    "INTERVAL_LOW = 32\n",
    "INTERVAL_HIGH = 72\n",
    "\n",
    "# Defaults for every part and note\n",
    "DEFAULT_BPM = 120\n",
    "DEFAULT_INSTRUMENT = 'Acoustic Grand Piano'\n",
    "DEFAULT_TIME_SIGNATURE = (3, 4)\n",
    "\n",
    "# How many parts our output will contain\n",
    "VOICE_NUM = 5\n",
    "\n",
    "# How should the parts be distributed in %\n",
    "VOICE_DISTRIBUTION = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "\n",
    "# Filter options\n",
    "VALID_TIME_SIGNATURES = [DEFAULT_TIME_SIGNATURE, (6, 8)]\n",
    "SCORE_PART_RATIO = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some health checks before we start\n",
    "test = 1.0 - np.sum(VOICE_DISTRIBUTION)\n",
    "if test > 0.001 or test < 0:\n",
    "    print('Warning: VOICE_DISTRIBUTION sum is not 1.0!')\n",
    "    \n",
    "if len(VOICE_DISTRIBUTION) != VOICE_NUM:\n",
    "    print('Warning: length of VOICE_DISTRIBUTION is not equals VOICE_NUM!')\n",
    "    \n",
    "if INTERVAL_HIGH - INTERVAL_LOW < 12:\n",
    "    print('Warning: Interval range is smaller than an octave!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_time(score, bpm, time_signature):\n",
    "    \"\"\"Gets the normalized duration of a score.\"\"\"\n",
    "    \n",
    "    # Get the score end time in seconds\n",
    "    end_time = math.ceil(score.get_end_time() * 10) / 10\n",
    "\n",
    "    # Calculate how long a measure is in seconds\n",
    "    beat_time = midi.qpm_to_bpm(60 / bpm, time_signature[0], time_signature[1])\n",
    "    measure_time = beat_time * time_signature[0]\n",
    "\n",
    "    # Normalize the end time to a well formed measure\n",
    "    end_time = end_time + (end_time % measure_time)\n",
    "    \n",
    "    return end_time\n",
    "\n",
    "def copy_note(note, offset=0):\n",
    "    \"\"\"Safely make a new note instance.\"\"\"\n",
    "    \n",
    "    return midi.Note(pitch=note.pitch,\n",
    "                     start=note.start + offset,\n",
    "                     end=note.end + offset,\n",
    "                     velocity=note.velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded \"./files/midi/symphony.mid\".\n"
     ]
    }
   ],
   "source": [
    "# Read MIDi file and clean up\n",
    "score = midi.PrettyMIDI(PATH_IN)\n",
    "score.remove_invalid_notes()\n",
    "print('Loaded \"{}\".'.format(PATH_IN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After import of the MIDI file we filter out uneeded time signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_time_signatures(score, valid_time_signatures, bpm, time_signature):\n",
    "    \"\"\"Filters notes by time signature.\"\"\"\n",
    "    \n",
    "    original_end_time = get_end_time(score, bpm, time_signature)\n",
    "    \n",
    "    # Detect times with correct time signatures\n",
    "    valid_times = []\n",
    "    valid_time = []\n",
    "\n",
    "    for signature in score.time_signature_changes:\n",
    "        is_valid_signature = False\n",
    "\n",
    "        for valid_signature in valid_time_signatures:\n",
    "            if (signature.numerator == valid_signature[0] and\n",
    "                signature.denominator == valid_signature[1]):\n",
    "                is_valid_signature = True\n",
    "                print('Found {}.'.format(signature))\n",
    "\n",
    "        if is_valid_signature:\n",
    "            if len(valid_time) == 1:\n",
    "                # Ignore this valid signature since we already have one.\n",
    "                continue\n",
    "\n",
    "            if len(valid_time) == 2:\n",
    "                # This is already full, save it!\n",
    "                valid_times.append(valid_time)\n",
    "\n",
    "            # Keep the start time of this valid time period\n",
    "            valid_time = [signature.time]\n",
    "\n",
    "        else:\n",
    "            # This is the end of a valid period\n",
    "            if len(valid_time) == 1:\n",
    "                valid_times.append([valid_time[0], signature.time])\n",
    "                valid_time = []\n",
    "\n",
    "    if len(valid_time) == 1:\n",
    "        valid_times.append([valid_time[0], original_end_time])\n",
    "\n",
    "    print('Total {} valid time frame(s).'.format(len(valid_times)))\n",
    "    \n",
    "    # Create a new score with only valid time signatures\n",
    "    new_score = midi.PrettyMIDI(initial_tempo=bpm)\n",
    "\n",
    "    for instrument in score.instruments:\n",
    "        new_instrument = midi.Instrument(program=instrument.program)\n",
    "        pitches = []\n",
    "        for note in instrument.notes:\n",
    "            offset = 0\n",
    "            for valid_time in valid_times:\n",
    "                offset += valid_time[0]\n",
    "                if not (note.end <= valid_time[0] or note.start >= valid_time[1]):\n",
    "                    new_instrument.notes.append(copy_note(note, -offset))\n",
    "        new_score.instruments.append(new_instrument)\n",
    "        \n",
    "    end_time = get_end_time(new_score, bpm, time_signature)\n",
    "    print('New score has a length of {0:.4} seconds (original was {1:.4} seconds).'.format(\n",
    "        end_time, original_end_time))\n",
    "    \n",
    "    if end_time / original_end_time < 0.1:\n",
    "        print('Warning: A large part of the original score was removed!')\n",
    "        \n",
    "    return new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3/4 at 0.00 seconds.\n",
      "Total 1 valid time frame(s).\n",
      "New score has a length of 42.9 seconds (original was 42.9 seconds).\n"
     ]
    }
   ],
   "source": [
    "# Remove invalid time signatures\n",
    "temp_score = filter_time_signatures(score, VALID_TIME_SIGNATURES, DEFAULT_BPM, DEFAULT_TIME_SIGNATURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check every single part of the score for its amount of notes in comparison to the whole score. If the ratio is very low (almost only empty staves) we ignore this part for later use (`SCORE_PART_RATIO`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sparse_parts(score, ratio):\n",
    "    \"\"\"Remove parts which are too sparse.\"\"\"\n",
    "\n",
    "    original_instruments_count = len(score.instruments)\n",
    "    original_notes_count = 0\n",
    "    for instrument in score.instruments:\n",
    "        original_notes_count += len(instrument.notes)\n",
    "        \n",
    "    removed_instruments = []\n",
    "\n",
    "    for instrument_index, instrument in enumerate(score.instruments):\n",
    "        instrument_notes_count = len(instrument.notes)\n",
    "        if instrument_notes_count == 0:\n",
    "            instrument_score_ratio = 0\n",
    "        else:\n",
    "            instrument_score_ratio = (instrument_notes_count / original_notes_count)\n",
    "\n",
    "        print('Part #{0} with a note ratio score of {1:.2%}'.format(\n",
    "            instrument_index + 1,\n",
    "            instrument_score_ratio))\n",
    "\n",
    "        if instrument_score_ratio < ratio:\n",
    "            removed_instruments.append(instrument_index)\n",
    "    \n",
    "    for instrument_index in reversed(removed_instruments):\n",
    "        del score.instruments[instrument_index]\n",
    "\n",
    "    print('Removed {} part(s), now {} given (original had {}).'.format(\n",
    "        original_instruments_count - len(score.instruments),\n",
    "        len(score.instruments),\n",
    "        original_instruments_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part #1 with a note ratio score of 11.90%\n",
      "Part #2 with a note ratio score of 11.52%\n",
      "Part #3 with a note ratio score of 10.63%\n",
      "Part #4 with a note ratio score of 5.57%\n",
      "Part #5 with a note ratio score of 0.89%\n",
      "Part #6 with a note ratio score of 5.57%\n",
      "Part #7 with a note ratio score of 1.52%\n",
      "Part #8 with a note ratio score of 14.56%\n",
      "Part #9 with a note ratio score of 6.71%\n",
      "Part #10 with a note ratio score of 11.65%\n",
      "Part #11 with a note ratio score of 13.42%\n",
      "Part #12 with a note ratio score of 6.08%\n",
      "Removed 4 part(s), now 8 given (original had 12).\n"
     ]
    }
   ],
   "source": [
    "# Remove sparse instruments\n",
    "remove_sparse_parts(temp_score, SCORE_PART_RATIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce all given parts to a smaller number we first analyze the ambitus of every part (not the instrument since this data might not always be correct) to then calculate a score (0 - 100%) of how likely this ambitus will fit into our new range based on `VOICE_DISTRIBUTION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_ambitus_groups(score, voice_num, voice_distribution):\n",
    "    \"\"\"Finds out which parts of the score belong to which ambitus group.\"\"\"\n",
    "\n",
    "    print('Identify ambitus groups for all score parts ..')\n",
    "\n",
    "    # 1. Analyze ambitus for every part\n",
    "    instrument_intervals = []\n",
    "    for instrument_index, instrument in enumerate(score.instruments):\n",
    "        pitches = []\n",
    "        for note in instrument.notes:\n",
    "            pitches.append(note.pitch)\n",
    "            \n",
    "        instrument_intervals.append([instrument_index,\n",
    "                                     min(pitches),\n",
    "                                     max(pitches)])\n",
    "\n",
    "    # 2. Identify minimum and maximum ambitus over all parts\n",
    "    instrument_intervals = np.array(instrument_intervals)\n",
    "    interval_min = np.min(instrument_intervals[:, 1])\n",
    "    interval_max = np.max(instrument_intervals[:, 2])\n",
    "    print('Score ambitus is {} - {} (min - max)!'.format(interval_min,\n",
    "                                                         interval_max))\n",
    "\n",
    "    # 3. Calculate closeness for every part to our groups\n",
    "    scores = []\n",
    "    interval_total = interval_max - interval_min\n",
    "    interval_slice = math.ceil(interval_total / voice_num)\n",
    "\n",
    "    range_min = interval_min - 1\n",
    "    for voice_index in range(0, voice_num):\n",
    "        range_min = interval_min + (interval_slice * voice_index) + 1\n",
    "        range_max = interval_min + (\n",
    "            interval_slice * voice_index) + interval_slice\n",
    "        for interval in instrument_intervals:\n",
    "            instrument_index, instrument_min, instrument_max = interval\n",
    "            closeness = abs(range_min - instrument_min) + abs(range_max - instrument_max)\n",
    "            closeness = 1 - (closeness / (interval_total * 2))\n",
    "            scores.append([instrument_index,\n",
    "                           voice_index,\n",
    "                           closeness])\n",
    "\n",
    "    # 4. Group parts based on closeness\n",
    "    instrument_groups = []\n",
    "    groups_count = [0 for i in range(0, voice_num)]\n",
    "\n",
    "    for interval in instrument_intervals:\n",
    "        # Filter all closeness scores belonging to this part ...\n",
    "        instrument_index = interval[0]\n",
    "        instrument_scores = list(filter(lambda i: i[0] == instrument_index, scores))\n",
    "        # ... sort them ...\n",
    "        instrument_scores = sorted(instrument_scores, key=lambda i: i[2], reverse=True)\n",
    "        # ... and take the group with the best score.\n",
    "        group_index = instrument_scores[0][1]\n",
    "        find_direction = True\n",
    "        while (groups_count[group_index] / len(instrument_intervals)\n",
    "               > voice_distribution[group_index]):\n",
    "            # Change group index when first choice was too full\n",
    "            if group_index == voice_num - 1:\n",
    "                find_direction = False\n",
    "            elif group_index == 0:\n",
    "                find_direction = True\n",
    "            group_index += 1 if find_direction else -1\n",
    "\n",
    "        instrument_groups.append(group_index)\n",
    "        groups_count[group_index] += 1\n",
    "\n",
    "    groups_count = np.array(groups_count)\n",
    "\n",
    "    # 5. Fill up empty spaces\n",
    "    while len(np.where(groups_count == 0)[0]) > 0:\n",
    "        empty_group_index = np.where(groups_count == 0)[0][0]\n",
    "        full_group_index = np.argmax(groups_count)\n",
    "        instrument_index = np.argwhere(instrument_groups == full_group_index).flatten()[0]\n",
    "        instrument_groups[instrument_index] = empty_group_index\n",
    "        groups_count[empty_group_index] += 1\n",
    "        groups_count[full_group_index] -= 1\n",
    "        print('Empty group {} detected, fill it up with part {}!'.format(\n",
    "            empty_group_index, instrument_index))\n",
    "\n",
    "    print('Parts in groups:', instrument_groups)\n",
    "\n",
    "    return np.array(instrument_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify ambitus groups for all score parts ..\n",
      "Score ambitus is 28 - 88 (min - max)!\n",
      "Parts in groups: [3, 3, 4, 4, 2, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Identify ambitus group for every instrument\n",
    "groups = identify_ambitus_groups(temp_score, VOICE_NUM, VOICE_DISTRIBUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transpose the notes into a defined range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(score, interval_min, interval_max):\n",
    "    \"\"\"Transpose all notes within a given interval.\"\"\"\n",
    "    \n",
    "    for instrument in score.instruments:\n",
    "        for note in instrument.notes:\n",
    "            normalized_pitch = note.pitch % 12\n",
    "            if note.pitch > interval_max:\n",
    "                normalized_interval = interval_max % 12\n",
    "                new_pitch = interval_max - normalized_interval - (12 - normalized_pitch)\n",
    "            elif note.pitch < interval_min:\n",
    "                normalized_interval = interval_min % 12\n",
    "                new_pitch = interval_min + normalized_interval + normalized_pitch\n",
    "            else:\n",
    "                new_pitch = note.pitch\n",
    "                \n",
    "            note.pitch = new_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose within an interval\n",
    "transpose(temp_score, INTERVAL_LOW, INTERVAL_HIGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we reduced the number of parts to x groups (`VOICE_NUM`) we will need to ignore original parts in the final score. To avoid this (and to augment our data), we don't throw away any unused parts but generate multiple scores in all different part combinations.\n",
    "\n",
    "The combinations are calculated by first translating the part groups into a tree structure to then traverse the tree from bottom up, finding all possible combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combination_tree(options, group_index):\n",
    "    \"\"\"Convert all possible combinations into a tree data structure.\"\"\"\n",
    "    \n",
    "    if len(options) - 1 < group_index:\n",
    "        return None\n",
    "    \n",
    "    combinations = []\n",
    "    \n",
    "    for option in options[group_index]:\n",
    "        combinations.append(option)\n",
    "        results = create_combination_tree(options, group_index + 1)\n",
    "        if results:\n",
    "            combinations.append(results)\n",
    "            \n",
    "    return combinations\n",
    "\n",
    "\n",
    "def traverse_combination_tree(tree, single_combination = [], result = [], depth = 0):\n",
    "    \"\"\"Traverse a tree to find all possible combinations.\"\"\"\n",
    "    \n",
    "    if not hasattr(tree, '__len__'):\n",
    "        return single_combination\n",
    "    \n",
    "    if depth == 0:\n",
    "        result = []\n",
    "        \n",
    "    if len(tree) == 1:\n",
    "        result.append(traverse_combination_tree(tree[0],\n",
    "                                                single_combination + [tree[0]],\n",
    "                                                result,\n",
    "                                                depth + 1))\n",
    "        \n",
    "    for i in range(0, len(tree) - 1, 2):\n",
    "        sub_tree = tree[i + 1]\n",
    "        if not hasattr(sub_tree, '__len__'):\n",
    "            for n in tree:\n",
    "                result.append(\n",
    "                    traverse_combination_tree(n,\n",
    "                                              single_combination + [n],\n",
    "                                              result,\n",
    "                                              depth + 1))\n",
    "        else:\n",
    "            traverse_combination_tree(sub_tree,\n",
    "                                      single_combination + [tree[i]],\n",
    "                                      result,\n",
    "                                      depth + 1)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts [7] in group 0 (size = 1).\n",
      "Parts [6] in group 1 (size = 1).\n",
      "Parts [4 5] in group 2 (size = 2).\n",
      "Parts [0 1] in group 3 (size = 2).\n",
      "Parts [2 3] in group 4 (size = 2).\n",
      "Found 8 possible combinations.\n"
     ]
    }
   ],
   "source": [
    "# Check which parts we can combine\n",
    "combination_options = []\n",
    "for group_index in range(0, VOICE_NUM):\n",
    "    options = np.argwhere(groups == group_index).flatten()\n",
    "    combination_options.append(options)\n",
    "    print('Parts {} in group {} (size = {}).'.format(\n",
    "        options, group_index, len(options)))\n",
    "\n",
    "# Build a tree to traverse to find all combinations\n",
    "tree = create_combination_tree(combination_options, 0)\n",
    "combinations = traverse_combination_tree(tree, single_combination=[])\n",
    "\n",
    "print('Found {} possible combinations.'.format(len(combinations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can generate a new score based on our temporary score with cleaned original parts and the given possible combinations. All combinations are simply just added up, the score grows in this way and yields more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated combination [7, 6, 4, 0, 2] #1.\n",
      "Generated combination [7, 6, 4, 0, 3] #2.\n",
      "Generated combination [7, 6, 4, 1, 2] #3.\n",
      "Generated combination [7, 6, 4, 1, 3] #4.\n",
      "Generated combination [7, 6, 5, 0, 2] #5.\n",
      "Generated combination [7, 6, 5, 0, 3] #6.\n",
      "Generated combination [7, 6, 5, 1, 2] #7.\n",
      "Generated combination [7, 6, 5, 1, 3] #8.\n",
      "Generated score with duration 342.0 seconds. Data augmentation of 697%!\n"
     ]
    }
   ],
   "source": [
    "# Prepare a new score with empty parts for every voice\n",
    "new_score = midi.PrettyMIDI(initial_tempo=DEFAULT_BPM)\n",
    "temp_end_time = get_end_time(temp_score, DEFAULT_BPM, DEFAULT_TIME_SIGNATURE)\n",
    "\n",
    "new_score.time_signature_changes = [midi.TimeSignature(\n",
    "    numerator=DEFAULT_TIME_SIGNATURE[0],\n",
    "    denominator=DEFAULT_TIME_SIGNATURE[1],\n",
    "    time=0.0)]\n",
    "\n",
    "for i in range(0, VOICE_NUM):\n",
    "    program = midi.instrument_name_to_program(DEFAULT_INSTRUMENT)\n",
    "    new_instrument = midi.Instrument(program=program)\n",
    "    new_score.instruments.append(new_instrument)\n",
    "\n",
    "# Add parts in all possible combinations\n",
    "for combination_index, combination in enumerate(combinations):\n",
    "    offset = combination_index * temp_end_time\n",
    "    for instrument_index, temp_instrument_index in enumerate(\n",
    "            reversed(combination)):\n",
    "        for note in temp_score.instruments[temp_instrument_index].notes:\n",
    "            new_score.instruments[instrument_index].notes.append(\n",
    "                copy_note(note, offset))\n",
    "            \n",
    "    print('Generated combination {} #{}.'.format(\n",
    "        combination, combination_index + 1))\n",
    "    \n",
    "# Done!\n",
    "new_end_time = get_end_time(new_score, DEFAULT_BPM, DEFAULT_TIME_SIGNATURE)\n",
    "print('Generated score with duration {0:.4} seconds. '\n",
    "      'Data augmentation of {1:.0%}!'.format(\n",
    "          new_end_time,\n",
    "          ((new_end_time / temp_end_time) - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write result to MIDI file\n",
    "new_score.write(PATH_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
